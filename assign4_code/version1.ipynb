{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- add None into test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import VisionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        img = img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "class DeepFashion(VisionDataset):\n",
    "    def __init__(self, csv_file, mode, transform):\n",
    "        self.mode = mode # train, test and val\n",
    "        self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "        \n",
    "        img_list = []\n",
    "        cate_list = []\n",
    "        attr_list = []\n",
    "        with open(csv_file) as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for line in reader:\n",
    "                img_list.append(line['file_path'])\n",
    "                if mode != 'test':\n",
    "                    cate = int(line['category_label'])\n",
    "                    cate_list.append(cate)\n",
    "                    \n",
    "                    attrs = tuple(line.values())[2:]\n",
    "                    attrs = [int(a) for a in attrs]\n",
    "                    attr_list.append(attrs) # save using tuple\n",
    "        self.img_list = img_list\n",
    "        self.cate_list = cate_list\n",
    "        self.attr_list = attr_list\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_list[idx]\n",
    "        img = pil_loader(path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            category = self.cate_list[idx]\n",
    "            category = torch.tensor(category)\n",
    "            attribute = torch.tensor(self.attr_list[idx])\n",
    "            return img, category, attribute\n",
    "        else:\n",
    "            return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train = transforms.Compose([\n",
    "    transforms.Resize(240),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.5, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "trans_test = transforms.Compose([\n",
    "    transforms.Resize(240),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "# target_trans = {32: 0, 33: 1, 3: 2, 6: 3, 41: 4,\n",
    "#                 11: 5, 16: 6, 17: 7, 18: 8, 19: 9}\n",
    "\n",
    "train_dataset = DeepFashion('deep_fashion/train.csv', 'train', trans_train)\n",
    "val_dataset = DeepFashion('deep_fashion/val.csv', 'val', trans_test)\n",
    "test_dataset = DeepFashion('deep_fashion/test.csv', 'test', trans_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39092\n",
      "39092\n",
      "39092\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset.img_list))\n",
    "print(len(train_dataset.cate_list))\n",
    "print(len(train_dataset.attr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 39092\n",
      "Val 5528\n",
      "Test 11225\n"
     ]
    }
   ],
   "source": [
    "print('Train', len(train_dataset))\n",
    "print('Val', len(val_dataset))\n",
    "print('Test', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "worker = 8\n",
    "train_data = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                        num_workers=worker, pin_memory=True,\n",
    "                        shuffle=True)\n",
    "val_data = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                        num_workers=worker, pin_memory=True)\n",
    "test_data = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        num_workers=worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENet 1_1\n",
    "model = models.squeezenet1_1(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.features[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# v2\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1)),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1)),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## resnet50\n",
    "# model = models.resnext50_32x4d(pretrained=True)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# in_features = model.fc.in_features\n",
    "# model.fc = nn.Linear(in_features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(params, lr=3e-5)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epoch, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    print('==========Train Epoch {}=========='.format(epoch))\n",
    "    loss_list = []\n",
    "    acc_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for i, (image, label, _) in tqdm(enumerate(data), ascii=True, total=len(data)):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        score = model(image) # predict the label\n",
    "        loss = criterion(score, label) # calculate error\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        pred = torch.argmax(score, dim=1)\n",
    "        correct = pred.eq(label)\n",
    "        acc_count += correct.sum().item()\n",
    "        total_count += image.shape[0]\n",
    "        \n",
    "        loss.backward()  # back-propagation\n",
    "        optimizer.step() # gradient descent\n",
    "\n",
    "    acc = acc_count / total_count * 100\n",
    "    return sum(loss_list) / len(loss_list), acc\n",
    "\n",
    "def test(model, data, criterion, device):\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "    acc_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for i, (image, label, _) in tqdm(enumerate(data), ascii=True, total=len(data)):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        score = model(image)\n",
    "        loss = criterion(score, label)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        pred = torch.argmax(score, dim=1)\n",
    "        correct = pred.eq(label)\n",
    "        acc_count += correct.sum().item()\n",
    "        total_count += image.shape[0]\n",
    "\n",
    "    acc = acc_count / total_count * 100\n",
    "    print('----------Acc: {}%----------'.format(acc))\n",
    "    return sum(loss_list) / len(loss_list), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Train Epoch 1==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 611/611 [00:27<00:00, 21.91it/s]\n",
      "100%|##########| 87/87 [00:03<00:00, 25.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Acc: 30.17366136034732%----------\n",
      "Cost 31.867602348327637 secs\n",
      "Train Acc: 21.285685 Train Loss: 2.182107\n",
      "Test Acc: 30.173661 Test Loss: 2.012580\n",
      "==========Train Epoch 2==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########| 611/611 [00:27<00:00, 22.50it/s]\n",
      "100%|##########| 87/87 [00:03<00:00, 26.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Acc: 35.07597684515195%----------\n",
      "Cost 31.084635496139526 secs\n",
      "Train Acc: 31.198199 Train Loss: 1.953731\n",
      "Test Acc: 35.075977 Test Loss: 1.887717\n",
      "==========Train Epoch 3==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########| 611/611 [00:26<00:00, 23.07it/s]\n",
      "100%|##########| 87/87 [00:03<00:00, 26.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Acc: 37.44573082489146%----------\n",
      "Cost 30.367223024368286 secs\n",
      "Train Acc: 33.679525 Train Loss: 1.888553\n",
      "Test Acc: 37.445731 Test Loss: 1.813228\n",
      "==========Train Epoch 4==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########| 611/611 [00:27<00:00, 22.14it/s]\n",
      "100%|##########| 87/87 [00:03<00:00, 26.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Acc: 38.83863965267728%----------\n",
      "Cost 31.49911594390869 secs\n",
      "Train Acc: 35.019953 Train Loss: 1.850375\n",
      "Test Acc: 38.838640 Test Loss: 1.769724\n",
      "==========Train Epoch 5==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########| 611/611 [00:26<00:00, 22.94it/s]\n",
      "100%|##########| 87/87 [00:03<00:00, 25.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Acc: 40.73806078147612%----------\n",
      "Cost 30.724737882614136 secs\n",
      "Train Acc: 36.275964 Train Loss: 1.824129\n",
      "Test Acc: 40.738061 Test Loss: 1.728970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "max_epochs = 5\n",
    "log_interval = 1\n",
    "\n",
    "train_acc_list = []\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    t = time.time()\n",
    "    train_loss, train_acc = train(model, train_data, epoch, criterion, optimizer, device)\n",
    "    val_loss, val_acc = test(model, val_data, criterion, device)\n",
    "    print('Cost', time.time() - t, 'secs')\n",
    "\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "    val_loss_list.append(val_loss)\n",
    "    if epoch % log_interval == 0:\n",
    "#         print('=' * 20, 'Epoch', epoch, '=' * 20)\n",
    "        print('Train Acc: {:.6f} Train Loss: {:.6f}'.format(train_acc, train_loss))\n",
    "        print('Test Acc: {:.6f} Test Loss: {:.6f}'.format(val_acc, val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
